{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ea3977-3ec4-4306-9161-6b5ce2ed9419",
   "metadata": {},
   "source": [
    "## **Langchainì„ í‘œí˜„í•˜ëŠ” ì–¸ì–´, LCEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af20af5-b90c-4dc5-a5b3-98ec344efc56",
   "metadata": {},
   "source": [
    "**[LCELë¡œ ê¸°ë³¸ ì²´ì¸ êµ¬ì„±í•˜ê¸°]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77edeeb-8a23-473e-a88a-fe92bb1d8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790c91c-13d8-4e63-9327-69ec498b8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install --upgrade --quiet langchain openai langchain-core langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b5ba43-bc2e-4190-99ae-ebc00a5d7029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the ice cream go to school?\\n\\nBecause it wanted to be a \"cool\" student! ğŸ¦ğŸ˜„'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "\n",
    "#LLM í˜¸ì¶œ\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "#ì¶œë ¥ íŒŒì„œ ì„¤ì •\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "#LCELë¡œ í”„ë¡¬í”„íŠ¸í…œí”Œë¦¿-LLM-ì¶œë ¥ íŒŒì„œ ì—°ê²°í•˜ê¸°\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "#invokeí•¨ìˆ˜ë¡œ chain ì‹¤í–‰í•˜ê¸°\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b8b84-b729-44d3-8ca5-1bc97a862d6c",
   "metadata": {},
   "source": [
    "**[Streaming ê¸°ëŠ¥ ì¶”ê°€ë¥¼ ë”ìš± ì‰½ê²Œ, stream()]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d775f392-7cc0-49d3-9328-a5417bfcedb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here you go:\n",
      "\n",
      "Why did the bear bring a suitcase to the picnic?\n",
      "\n",
      "Because it wanted to pack a punchline! ğŸ»ğŸ’"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Chain ì„ ì–¸\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "chain = prompt | model\n",
    "\n",
    "#Chainì˜ stream()í•¨ìˆ˜ë¥¼ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ ì¶”ê°€\n",
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c95df4-97eb-436e-bc7c-49e5ef6bcfc6",
   "metadata": {},
   "source": [
    "**[í•œêº¼ë²ˆì— ì—¬ëŸ¬ ê°œ API ìš”ì²­í•˜ê³  ë‹µë³€ ë°›ê¸°, batch()]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed14ec-6976-4dcb-885e-3e3881db709a",
   "metadata": {},
   "source": [
    "- 5ê°œ ë¬¸ì¥ ë²ˆì—­ batch ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8acd216-87fb-4d1c-9de6-4e0a586e9889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 531 ms\n",
      "Wall time: 2.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Elle lit un livre tous les matins.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 33, 'total_tokens': 42}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'finish_reason': 'stop', 'logprobs': None}, id='run-6b498416-a264-4ae7-b6ab-edd711be2415-0'),\n",
       " AIMessage(content=\"Aujourd'hui, il fait vraiment beau.\", response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 30, 'total_tokens': 38}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'finish_reason': 'stop', 'logprobs': None}, id='run-d8d3bdfb-0b3c-4821-8b91-9e5342051229-0'),\n",
       " AIMessage(content='Le soir, je vais regarder un film avec mes amis.', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 34, 'total_tokens': 46}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'finish_reason': 'stop', 'logprobs': None}, id='run-12518210-35a7-419a-95de-1975607cadb1-0'),\n",
       " AIMessage(content='ê·¸ í•™ìƒì€ ë§¤ìš° ì„±ì‹¤í•˜ê²Œ ê³µë¶€í•©ë‹ˆë‹¤. -> Cet Ã©lÃ¨ve Ã©tudie trÃ¨s assidÃ»ment.', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 32, 'total_tokens': 55}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'finish_reason': 'stop', 'logprobs': None}, id='run-687141ec-b430-4d97-af35-0d40f1c2b5c6-0'),\n",
       " AIMessage(content='Il me faut juste une tasse de cafÃ© maintenant.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 35, 'total_tokens': 45}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'finish_reason': 'stop', 'logprobs': None}, id='run-fbf4d0f8-7384-44d8-82b1-c7ca46240f65-0')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "prompt = ChatPromptTemplate.from_template(\"ë‹¤ìŒ í•œê¸€ ë¬¸ì¥ì„ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•´ì¤˜ {sentence}\")\n",
    "chain = prompt | model\n",
    "\n",
    "chain.batch([\n",
    "    {\"sentence\": \"ê·¸ë…€ëŠ” ë§¤ì¼ ì•„ì¹¨ ì±…ì„ ì½ìŠµë‹ˆë‹¤.\"}, \n",
    "    {\"sentence\": \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì°¸ ì¢‹ë„¤ìš”.\"},\n",
    "    {\"sentence\": \"ì €ë…ì— ì¹œêµ¬ë“¤ê³¼ ì˜í™”ë¥¼ ë³¼ ê±°ì˜ˆìš”.\"},\n",
    "    {\"sentence\": \"ê·¸ í•™ìƒì€ ë§¤ìš° ì„±ì‹¤í•˜ê²Œ ê³µë¶€í•©ë‹ˆë‹¤.\"},\n",
    "    {\"sentence\": \"ì»¤í”¼ í•œ ì”ì´ ì§€ê¸ˆ ë”± í•„ìš”í•´ìš”.\"}\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8525cc5-caa8-4768-b8ad-a3136c098738",
   "metadata": {},
   "source": [
    "- 1ê°œ ë¬¸ì¥ ë²ˆì—­ invoke ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc3a3d6-f717-4782-9ed7-537bd32ddddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 688 ms\n",
      "Wall time: 1.93 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Elle lit un livre tous les matins.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 44, 'total_tokens': 54}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0cce54c7-6aaa-4206-b879-e49800371065-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = ChatOpenAI(openai_api_key=\"YOUR_API_KEY\")\n",
    "prompt = ChatPromptTemplate.from_template(\"ë‹¤ìŒ í•œê¸€ ë¬¸ì¥ì„ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•´ì¤˜ {sentence}\")\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"sentence\": \"ê·¸ë…€ëŠ” ë§¤ì¼ ì•„ì¹¨ ì±…ì„ ì½ìŠµë‹ˆë‹¤.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f084d6-f035-4a12-937d-b192e9678180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
