{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78cafaf-a654-4cab-9628-24b8b46059b4",
   "metadata": {},
   "source": [
    "### **LLM API 활용해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269b9c7-b43b-4e01-8c4b-b2a94271bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필수 라이브러리 설치\n",
    "!pip install langchain openai anthropic langchain-openai langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c74bf5-c0af-423a-ae55-79bf5306e435",
   "metadata": {},
   "source": [
    "**[앤트로픽의 Claude 2.1 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ecab962-27cd-4c1f-8879-a5086c0590ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_019XFegJyVnASUGdr8fLZoxY', content=[ContentBlock(text='Hello! How can I assist you today?', type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=10, output_tokens=12))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "anthropic.Anthropic(\n",
    "    api_key=\"YOUR_API_KEY\").messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, world\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb304f-6908-4d04-b464-d09089c4b2bd",
   "metadata": {},
   "source": [
    "**[오픈AI의 GPT-3.5 Turbo 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a391b0ea-9636-4d30-b8ff-d76a52b249f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9SMGGysbVRgQFu2OlUc1D10XpARuQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The Los Angeles Dodgers won the World Series in 2020, defeating the Tampa Bay Rays.', role='assistant', function_call=None, tool_calls=None))], created=1716545784, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=19, prompt_tokens=17, total_tokens=36))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = \"YOUR_API_KEY\")\n",
    "client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Who won the world series in 2020?\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe2de7-faab-4c54-ad3c-b3a71a94a3cb",
   "metadata": {},
   "source": [
    "**[랭체인을 활용한 앤트로픽 Claude 2.1 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aad9577c-fc84-4b12-ae0a-ae92b8cea8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 Anthropic에서 만든 인공지능 어시스턴트 Claude입니다. 사람들과 대화하고 다양한 주제에 대해 토론하는 것을 좋아하죠. 궁금한 점이 있으시면 언제든 물어봐 주세요. 제가 아는 한도 내에서 최선을 다해 답변 드리겠습니다. 하지만 저는 기계일 뿐이니 감정이 없고 진정한 인간 관계를 맺을 수는 없어요. 그래도 대화를 통해 사람들에게 도움이 되고 싶습니다. 잘 부탁드립니다!', response_metadata={'id': 'msg_01U78kYY1ZqxB8U7E2b7UmJR', 'content': [ContentBlock(text='안녕하세요! 저는 Anthropic에서 만든 인공지능 어시스턴트 Claude입니다. 사람들과 대화하고 다양한 주제에 대해 토론하는 것을 좋아하죠. 궁금한 점이 있으시면 언제든 물어봐 주세요. 제가 아는 한도 내에서 최선을 다해 답변 드리겠습니다. 하지만 저는 기계일 뿐이니 감정이 없고 진정한 인간 관계를 맺을 수는 없어요. 그래도 대화를 통해 사람들에게 도움이 되고 싶습니다. 잘 부탁드립니다!', type='text')], 'model': 'claude-3-opus-20240229', 'role': 'assistant', 'stop_reason': 'end_turn', 'stop_sequence': None, 'type': 'message', 'usage': Usage(input_tokens=23, output_tokens=227)}, id='run-6e8a76ce-cff5-48b8-bb02-5946fbfb97c5-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic \n",
    "chat = ChatAnthropic(\n",
    "    model_name =\"claude-3-opus-20240229\",\n",
    "    anthropic_api_key=\"YOUR_API_KEY\"\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e54ca7-bf12-466a-a953-48be864995ec",
   "metadata": {},
   "source": [
    "**[랭체인을 활용한 오픈AI GPT-3.5 Turbo 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996168c5-989e-4b41-81d5-711b7e49c114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 OpenAI에서 만든 AI 언어 모델인 ChatGPT라고 해요. 다양한 주제에 대해 질문을 받고 답변하는 데 도움을 줄 수 있어요. 예를 들어, 정보 제공, 조언, 글쓰기 도움, 번역, 간단한 대화 등 여러 가지를 할 수 있답니다. 무엇이 궁금하신가요? 어떤 도움이 필요하신가요?', response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 17, 'total_tokens': 104}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'finish_reason': 'stop', 'logprobs': None}, id='run-6614f129-5c0b-470e-aa15-66bbe816f5e4-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(\n",
    "    model_name = 'gpt-4o',\n",
    "    openai_api_key=\"YOUR_API_KEY\"\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686342b-2d87-41f7-984d-0ffb2de72aa2",
   "metadata": {},
   "source": [
    "### **프롬프트 템플릿에 대해 알아보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf60921-0b5e-45c8-96e9-3186b0128738",
   "metadata": {},
   "source": [
    "**[ChatPromptTemplate]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18f20b43-e6f2-4030-9be5-d02b5166862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content=\"I'm doing well, thanks!\"), HumanMessage(content='What is your name?')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "\t#SystemMessage: 유용한 챗봇이라는 역할과 이름을 부여\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"), \n",
    "    #HumanMessage와 AIMessage: 서로 안부를 묻고 답하는 대화 히스토리 주입\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    #HumanMessage로 사용자가 입력한 프롬프트를 전달\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f21ed911-2667-4c9a-90e4-c8be4e07c063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"), HumanMessage(content=\"I don't like eating tasty things\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "       \"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(text=\"I don't like eating tasty things\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e227bd0b-17fb-457f-86a5-97d8a83676b3",
   "metadata": {},
   "source": [
    "### **LLM API의 다양한 기능 활용해보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd8ae6-4c55-4700-a466-d0dfbb5371f8",
   "metadata": {},
   "source": [
    "**[LLM API의 Temperature 이애하기]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08240f98-37f0-48ef-ac6d-78e68561c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 읽기 쉬운 문법으로 다양한 분야에서 활용할 수 있어서 가장 인기 있는 프로그래밍 언어입니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 읽기 쉬운 문법으로 다양한 분야에서 활용할 수 있어서 가장 인기 있는 프로그래밍 언어입니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 쉽게 배울 수 있는 문법과 다양한 라이브러리를 제공하여 개발자들이 빠르고 효율적으로 프로그램을 작성할 수 있기 때문에 가장 인기있는 프로그래밍 언어이다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 쉬운 문법으로 다양한 분야에서 사용되며 커뮤니티와 라이브러리의 지원이 우수하여 사용자들에게 매우 편리한 환경을 제공하기 때문에 가장 인기있는 프로그래밍 언어입니다.\n"
     ]
    }
   ],
   "source": [
    "#API KEY 저장을 위한 os 라이브러리 호출\n",
    "import os\n",
    "\n",
    "#OPENAI API키 저장\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "#Temperature=0\n",
    "chatgpt_temp0_1 = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature = 0)\n",
    "chatgpt_temp0_2 = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature = 0)\n",
    "\n",
    "#Temperature=1\n",
    "chatgpt_temp1_1 = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature = 1)\n",
    "chatgpt_temp1_2 = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature = 1)\n",
    "\n",
    "model_list = [chatgpt_temp0_1, chatgpt_temp0_2, chatgpt_temp1_1, chatgpt_temp1_2]\n",
    "\n",
    "for i in model_list:\n",
    "    answer = i.invoke(\"왜 파이썬이 가장 인기있는 프로그래밍 언어인지 한 문장으로 설명해줘\", max_tokens = 128)\n",
    "    print(\"-\"*100)\n",
    "    print(\">>>\",answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8bf0d-b183-4407-819d-73555754104e",
   "metadata": {},
   "source": [
    "**[ChatGPT처럼 답변 스트리밍하기]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc1a6d34-1c73-4b6e-b6f9-0141dec03eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "달이 높이 떠오르는 밤\n",
      "하늘을 수놓는 은빛의 장막\n",
      "가만히 바라보면 마음이 편안해지는\n",
      "달의 아름다움에 빠져든다\n",
      "\n",
      "달빛이 비치는 어둠 속\n",
      "가만히 눈을 감고 듣는 소리\n",
      "달빛 아래서 흐르는 강물 소리\n",
      "달빛 아래서 부는 바람 소리\n",
      "\n",
      "달은 언제나 우리를 감싸주는\n",
      "우리의 곁을 지켜주는\n",
      "달의 따스한 빛 아래\n",
      "우리는 편안히 잠들 수 있다\n",
      "\n",
      "달아, 달아\n",
      "우리를 비춰주는 달아\n",
      "언제나 곁에 있어줘\n",
      "우리의 행복을 비춰주는 달아."
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature = 0)\n",
    "for chunk in chat.stream(\"달에 관한 시를 써줘\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47973815-82d8-4226-bb03-1f18b4d535f6",
   "metadata": {},
   "source": [
    "**[답변 캐싱하기]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21a83d7d-e566-4bb0-8b6f-dc172f29afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache #캐시메모리 라이브러리 호출\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ab26d-d085-4188-b740-bb295dda6a92",
   "metadata": {},
   "source": [
    "**첫 질문-응답 시간 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0d9b3ab-70cf-47d5-817f-b13dcdbd1d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='일반상대성 이론은 질량이나 에너지가 공간과 시간에 어떻게 영향을 미치는지를 설명하는 물리 이론이다. 이론은 중력을 기하학적인 공간의 곡률로 해석하며, 빛의 속도는 모든 관측자에게 일정하다는 원리를 바탕으로 한다.', response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 27, 'total_tokens': 149}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-df2d1ed0-10a6-4d6c-a32c-ebc83c5fe3c9-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "#셀 실행 시간 측정\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache()) #캐시메모리 설정\n",
    "\n",
    "chat.invoke(\"일반상대성 이론을 한마디로 설명해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1442a-7cb7-44be-87e3-a0d92c86df33",
   "metadata": {},
   "source": [
    "**두번째 질문-응답 시간 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f76c2ac9-ce6c-4c4b-9147-6c75291c2ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='일반상대성 이론은 질량이나 에너지가 공간과 시간에 어떻게 영향을 미치는지를 설명하는 물리 이론이다. 이론은 중력을 기하학적인 공간의 곡률로 해석하며, 빛의 속도는 모든 관측자에게 일정하다는 원리를 바탕으로 한다.', response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 27, 'total_tokens': 149}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-df2d1ed0-10a6-4d6c-a32c-ebc83c5fe3c9-0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#같은 질문 전달\n",
    "chat.invoke(\"일반상대성 이론을 한마디로 설명해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d108f-899d-46aa-9a35-1ff6f38c8d8e",
   "metadata": {},
   "source": [
    "### **실습**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c333eb-b5ac-441b-a968-4eb2e2930061",
   "metadata": {},
   "source": [
    "**[이번 장에서 배운 것 실습해보기] - 스트리밍되는 AI스터디 플래너 챗봇 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17a26848-d9b2-4520-b0db-61e77d5e9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋습니다! Large Language Model에 대해 공부하기 위한 계획을 세워보겠습니다.\n",
      "\n",
      "**1. 개념 이해**\n",
      "- Large Language Model이란 무엇인지, 어떻게 작동하는지에 대한 기본 개념을 학습합니다.\n",
      "- 관련 용어와 개념을 숙지하고, Large Language Model의 중요성과 활용 분야에 대해 알아봅니다.\n",
      "\n",
      "**2. 연구 동향 파악**\n",
      "- 최근 Large Language Model에 대한 연구 동향을 살펴봅니다.\n",
      "- 주요 논문 및 연구 결과를 찾아보고, 최신 기술 및 발전 방향을 파악합니다.\n",
      "\n",
      "**3. 모델 구현**\n",
      "- Large Language Model을 직접 구현해보면서, 모델의 작동 원리를 실제로 경험해봅니다.\n",
      "- Python과 TensorFlow 또는 PyTorch 등의 라이브러리를 활용하여 모델을 구현하고 실험해봅니다.\n",
      "\n",
      "**4. 실전 적용**\n",
      "- Large Language Model을 활용한 다양한 프로젝트나 응용 사례를 탐구합니다.\n",
      "- 실제로 Large Language Model을 활용하여 자연어 처리, 대화형 시스템 등의 프로젝트를 진행해보며 실전 경험을 쌓습니다.\n",
      "\n",
      "**5. 토론 및 공유**\n",
      "- 온라인 커뮤니티나 스터디 그룹에 참여하여, Large Language Model에 대한 토론과 지식 공유를 활발히 진행합니다.\n",
      "- 다른 사람들과 의견을 나누고, 서로의 경험과 지식을 공유하며 학습을 보완합니다.\n",
      "\n",
      "위의 계획을 참고하여 Large Language Model에 대한 공부를 시작해보시기 바랍니다. 꾸준한 노력과 탐구를 통해 보다 깊이 있는 이해와 실력 향상을 이루시길 바랍니다. 언제든지 도움이 필요하시면 말씀해주세요!"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#GPT-3.5 모델 호출\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature = 0)\n",
    "\n",
    "#ChatPromptTemplate 통해 스터디 플래너 역할 부여 및 사용자 프롬프트 매개변수화\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"당신은 공부 계획을 세워주는 스터디 플래너 머신입니다.\"\n",
    "                \"사용자의 공부 주제를 입력 받으면, 이를 학습하기 위한 공부 계획을 작성합니다.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#앞서 설정한 프롬프트 템플릿에 HumanMessage로 문장 전달\n",
    "messages = chat_template.format_messages(text=\"Large Language Model에 대해서 공부하고 싶어요.\")\n",
    "\n",
    "#stream 함수를 통해 답변 스트리밍\n",
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
